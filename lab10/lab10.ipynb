{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Language modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, BertForMaskedLM, BertTokenizer, pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Download three Polish models from the Huggingface repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dkleczek/bert-base-polish-cased-v1 were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "bert_cased_model = BertForMaskedLM.from_pretrained(\"dkleczek/bert-base-polish-cased-v1\")\n",
    "bert_cased_tokenizer = BertTokenizer.from_pretrained(\"dkleczek/bert-base-polish-cased-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at allegro/herbert-base-cased were not used when initializing BertForMaskedLM: ['cls.sso.sso_relationship.weight', 'cls.sso.sso_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "herbert_cased_model = BertForMaskedLM.from_pretrained(\"allegro/herbert-base-cased\")\n",
    "herbert_cased_tokenizer = AutoTokenizer.from_pretrained(\"allegro/herbert-base-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "637ab10a886e4b40863d2be7ce13104a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=547.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2033923bcfca4ff880bac5ee2439b8ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=499534190.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForMaskedLM were not initialized from the model checkpoint at allegro/herbert-klej-cased-v1 and are newly initialized: ['cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bf9ffb137ae43a4a7dbbaa986eb3321",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=25.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b85b645eb0248a794a849d4878c39b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=1037897.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e5c215b1005402cafc8425438cf59e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=590648.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e593992ccdc4d28a0b14442d37be654",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=300.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1301a93e5087426b90a7675e3bf6899f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=341.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "herbert_klej_cased_model = BertForMaskedLM.from_pretrained(\"allegro/herbert-klej-cased-v1\")\n",
    "herbert_klej_cased_tokenizer = AutoTokenizer.from_pretrained(\"allegro/herbert-klej-cased-tokenizer-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [bert_cased_model, herbert_cased_model, herbert_klej_cased_model]\n",
    "models_names = ['bert_cased_model', 'allegro/herbert-base-cased', 'allegro/herbert-klej-cased-v1']\n",
    "tokenizers = [bert_cased_tokenizer, herbert_cased_tokenizer, herbert_klej_cased_tokenizer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentences_each_model(sentences):\n",
    "    for sentence in sentences:\n",
    "        for i in range(len(models)):\n",
    "            print(str(models_names[i]))\n",
    "            if models[i] == herbert_cased_model:\n",
    "                sentence = sentence.replace('[MASK]','<mask>')\n",
    "            nlp = pipeline('fill-mask', model=models[i], tokenizer=tokenizers[i])\n",
    "            predictions = nlp(sentence)\n",
    "            predicted_sentences = [prediction['sequence'] for prediction in predictions]\n",
    "            for predicted_sentence in predicted_sentences:\n",
    "                predicted_sentence = predicted_sentence.replace('[CLS] ', '').replace(' [SEP]', '')\n",
    "                if '<s>' in predicted_sentence:\n",
    "                    predicted_sentence = predicted_sentence.replace('<s>', '')\n",
    "                    predicted_sentence = predicted_sentence.replace(' </s>', '')\n",
    "                print('   ' + predicted_sentence)\n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Produce the predictions for the following sentences (use each model and check 5 predictions):\n",
    "1. (M) Warszawa to największe [MASK].\n",
    "2. (D) Te zabawki należą do [MASK].\n",
    "3. (C) Policjant przygląda się [MASK].\n",
    "4. (B) Na środku skrzyżowania widać [MASK].\n",
    "5. (N) Właściciel samochodu widział złodzieja z [MASK].\n",
    "6. (Ms) Prezydent z premierem rozmawiali wczoraj o [MASK].\n",
    "7. (W) Witaj drogi [MASK]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [f\"Warszawa to największe [MASK].\",\n",
    "            f\"Te zabawki należą do [MASK].\",\n",
    "            f\"Policjant przygląda się [MASK].\",\n",
    "            f\"Na środku skrzyżowania widać [MASK].\",\n",
    "            f\"Właściciel samochodu widział złodzieja z [MASK].\",\n",
    "            f\"Prezydent z premierem rozmawiali wczoraj o [MASK].\",\n",
    "            f\"Witaj drogi [MASK].\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert_cased_model\n",
      "   Warszawa to największe miasto.\n",
      "   Warszawa to największe województwo.\n",
      "   Warszawa to największe lotnisko.\n",
      "   Warszawa to największe miasteczko.\n",
      "   Warszawa to największe państwo.\n",
      "allegro/herbert-base-cased\n",
      "   Warszawa to największe miasto.\n",
      "   Warszawa to największe lotnisko.\n",
      "   Warszawa to największe centrum.\n",
      "   Warszawa to największe miasta.\n",
      "   Warszawa to największe atrakcje.\n",
      "allegro/herbert-klej-cased-v1\n",
      "   Warszawa to największe zrozumiał.\n",
      "   Warszawa to największe Telewizji.\n",
      "   Warszawa to największe Telewizja.\n",
      "   Warszawa to największe wałam.\n",
      "   Warszawa to największe zawiera.\n",
      "\n",
      "\n",
      "bert_cased_model\n",
      "   Te zabawki należą do ciebie.\n",
      "   Te zabawki należą do mnie.\n",
      "   Te zabawki należą do nas.\n",
      "   Te zabawki należą do pana.\n",
      "   Te zabawki należą do niego.\n",
      "allegro/herbert-base-cased\n",
      "   Te zabawki należą do rodziny.\n",
      "   Te zabawki należą do nas.\n",
      "   Te zabawki należą do nich.\n",
      "   Te zabawki należą do najlepszych.\n",
      "   Te zabawki należą do..\n",
      "allegro/herbert-klej-cased-v1\n",
      "   Te zabawki należą do proble.\n",
      "   Te zabawki należą do ósł.\n",
      "   Te zabawki należą do Izrael.\n",
      "   Te zabawki należą do zagłady.\n",
      "   Te zabawki należą do wątpliwość.\n",
      "\n",
      "\n",
      "bert_cased_model\n",
      "   Policjant przygląda się temu.\n",
      "   Policjant przygląda się sprawie.\n",
      "   Policjant przygląda się im.\n",
      "   Policjant przygląda się wszystkiemu.\n",
      "   Policjant przygląda się panu.\n",
      "allegro/herbert-base-cased\n",
      "   Policjant przygląda się mężczyźnie.\n",
      "   Policjant przygląda się kobiecie.\n",
      "   Policjant przygląda się mu.\n",
      "   Policjant przygląda się dziewczynie.\n",
      "   Policjant przygląda się sprawie.\n",
      "allegro/herbert-klej-cased-v1\n",
      "   Policjant przygląda się przewidywanych.\n",
      "   Policjant przygląda się H..\n",
      "   Policjant przygląda się rocznych.\n",
      "   Policjant przygląda się mówieniu.\n",
      "   Policjant przygląda się prognoz.\n",
      "\n",
      "\n",
      "bert_cased_model\n",
      "   Na środku skrzyżowania widać rzekę.\n",
      "   Na środku skrzyżowania widać ulicę.\n",
      "   Na środku skrzyżowania widać drzewa.\n",
      "   Na środku skrzyżowania widać drogę.\n",
      "   Na środku skrzyżowania widać las.\n",
      "allegro/herbert-base-cased\n",
      "   Na środku skrzyżowania widać rondo.\n",
      "   Na środku skrzyżowania widać samochody.\n",
      "   Na środku skrzyżowania widać radiowóz.\n",
      "   Na środku skrzyżowania widać samochód.\n",
      "   Na środku skrzyżowania widać wiadukt.\n",
      "allegro/herbert-klej-cased-v1\n",
      "   Na środku skrzyżowania widać Energii.\n",
      "   Na środku skrzyżowania widać EM.\n",
      "   Na środku skrzyżowania widać następującymi.\n",
      "   Na środku skrzyżowania widać składowania.\n",
      "   Na środku skrzyżowania widać żem.\n",
      "\n",
      "\n",
      "bert_cased_model\n",
      "   Właściciel samochodu widział złodzieja z bronią.\n",
      "   Właściciel samochodu widział złodzieja z tyłu.\n",
      "   Właściciel samochodu widział złodzieja z ulicy.\n",
      "   Właściciel samochodu widział złodzieja z bliska.\n",
      "   Właściciel samochodu widział złodzieja z zewnątrz.\n",
      "allegro/herbert-base-cased\n",
      "   Właściciel samochodu widział złodzieja z samochodu.\n",
      "   Właściciel samochodu widział złodzieja z włamaniem.\n",
      "   Właściciel samochodu widział złodzieja z auta.\n",
      "   Właściciel samochodu widział złodzieja z kierowcą.\n",
      "   Właściciel samochodu widział złodzieja z parkingu.\n",
      "allegro/herbert-klej-cased-v1\n",
      "   Właściciel samochodu widział złodzieja z ANI.\n",
      "   Właściciel samochodu widział złodzieja z Wersja.\n",
      "   Właściciel samochodu widział złodzieja z charakterystyczny.\n",
      "   Właściciel samochodu widział złodzieja z począwszy.\n",
      "   Właściciel samochodu widział złodzieja z gatunku.\n",
      "\n",
      "\n",
      "bert_cased_model\n",
      "   Prezydent z premierem rozmawiali wczoraj o tym.\n",
      "   Prezydent z premierem rozmawiali wczoraj o Polsce.\n",
      "   Prezydent z premierem rozmawiali wczoraj o budżecie.\n",
      "   Prezydent z premierem rozmawiali wczoraj o ASF.\n",
      "   Prezydent z premierem rozmawiali wczoraj o ustawie.\n",
      "allegro/herbert-base-cased\n",
      "   Prezydent z premierem rozmawiali wczoraj o przyszłości.\n",
      "   Prezydent z premierem rozmawiali wczoraj o Polsce.\n",
      "   Prezydent z premierem rozmawiali wczoraj o bezpieczeństwie.\n",
      "   Prezydent z premierem rozmawiali wczoraj o polityce.\n",
      "   Prezydent z premierem rozmawiali wczoraj o Warszawie.\n",
      "allegro/herbert-klej-cased-v1\n",
      "   Prezydent z premierem rozmawiali wczoraj o opiece.\n",
      "   Prezydent z premierem rozmawiali wczoraj o Mali.\n",
      "   Prezydent z premierem rozmawiali wczoraj o przywód.\n",
      "   Prezydent z premierem rozmawiali wczoraj o mówieniu.\n",
      "   Prezydent z premierem rozmawiali wczoraj o występowania.\n",
      "\n",
      "\n",
      "bert_cased_model\n",
      "   Witaj drogi chłopcze.\n",
      "   Witaj drogi przyjacielu.\n",
      "   Witaj drogi bracie.\n",
      "   Witaj drogi kolego.\n",
      "   Witaj drogi synu.\n",
      "allegro/herbert-base-cased\n",
      "   Witaj drogi Łukasz.\n",
      "   Witaj drogi Boże.\n",
      "   Witaj drogi człowieku.\n",
      "   Witaj drogi Karol.\n",
      "   Witaj drogi Marcin.\n",
      "allegro/herbert-klej-cased-v1\n",
      "   Witaj drogi stanowiącym.\n",
      "   Witaj drogi zrozumiał.\n",
      "   Witaj drogi tałem.\n",
      "   Witaj drogi lip.\n",
      "   Witaj drogi któreg.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predict_sentences_each_model(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Check the model predictions for the following sentences (using each model):\n",
    "1. Gdybym wiedział wtedy dokładnie to co wiem teraz, to bym się nie [MASK].\n",
    "2. Gdybym wiedziała wtedy dokładnie to co wiem teraz, to bym się nie [MASK]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences2 = [f\"Gdybym wiedział wtedy dokładnie to co wiem teraz, to bym się nie [MASK].\",\n",
    "             f\"Gdybym wiedziała wtedy dokładnie to co wiem teraz, to bym się nie [MASK].\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert_cased_model\n",
      "   Gdybym wiedział wtedy dokładnie to co wiem teraz, to bym się nie zgodził.\n",
      "   Gdybym wiedział wtedy dokładnie to co wiem teraz, to bym się nie dowiedział.\n",
      "   Gdybym wiedział wtedy dokładnie to co wiem teraz, to bym się nie martwił.\n",
      "   Gdybym wiedział wtedy dokładnie to co wiem teraz, to bym się nie bał.\n",
      "   Gdybym wiedział wtedy dokładnie to co wiem teraz, to bym się nie zabił.\n",
      "allegro/herbert-base-cased\n",
      "   Gdybym wiedział wtedy dokładnie to co wiem teraz, to bym się nie zdziwił.\n",
      "   Gdybym wiedział wtedy dokładnie to co wiem teraz, to bym się nie poddał.\n",
      "   Gdybym wiedział wtedy dokładnie to co wiem teraz, to bym się nie dowiedział.\n",
      "   Gdybym wiedział wtedy dokładnie to co wiem teraz, to bym się nie zastanawiał.\n",
      "   Gdybym wiedział wtedy dokładnie to co wiem teraz, to bym się nie przyznał.\n",
      "allegro/herbert-klej-cased-v1\n",
      "   Gdybym wiedział wtedy dokładnie to co wiem teraz, to bym się nie astro.\n",
      "   Gdybym wiedział wtedy dokładnie to co wiem teraz, to bym się nie rzeczywisty.\n",
      "   Gdybym wiedział wtedy dokładnie to co wiem teraz, to bym się nie zdał.\n",
      "   Gdybym wiedział wtedy dokładnie to co wiem teraz, to bym się nie poza.\n",
      "   Gdybym wiedział wtedy dokładnie to co wiem teraz, to bym się nie +.\n",
      "\n",
      "\n",
      "bert_cased_model\n",
      "   Gdybym wiedziała wtedy dokładnie to co wiem teraz, to bym się nie zgodziła.\n",
      "   Gdybym wiedziała wtedy dokładnie to co wiem teraz, to bym się nie bała.\n",
      "   Gdybym wiedziała wtedy dokładnie to co wiem teraz, to bym się nie dowiedziała.\n",
      "   Gdybym wiedziała wtedy dokładnie to co wiem teraz, to bym się nie zabiła.\n",
      "   Gdybym wiedziała wtedy dokładnie to co wiem teraz, to bym się nie pojawiła.\n",
      "allegro/herbert-base-cased\n",
      "   Gdybym wiedziała wtedy dokładnie to co wiem teraz, to bym się nie dowiedziała.\n",
      "   Gdybym wiedziała wtedy dokładnie to co wiem teraz, to bym się nie przyznała.\n",
      "   Gdybym wiedziała wtedy dokładnie to co wiem teraz, to bym się nie bała.\n",
      "   Gdybym wiedziała wtedy dokładnie to co wiem teraz, to bym się nie śmiała.\n",
      "   Gdybym wiedziała wtedy dokładnie to co wiem teraz, to bym się nie zmieniła.\n",
      "allegro/herbert-klej-cased-v1\n",
      "   Gdybym wiedziała wtedy dokładnie to co wiem teraz, to bym się nie astro.\n",
      "   Gdybym wiedziała wtedy dokładnie to co wiem teraz, to bym się nie rzeczywisty.\n",
      "   Gdybym wiedziała wtedy dokładnie to co wiem teraz, to bym się nie zdał.\n",
      "   Gdybym wiedziała wtedy dokładnie to co wiem teraz, to bym się nie +.\n",
      "   Gdybym wiedziała wtedy dokładnie to co wiem teraz, to bym się nie poza.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predict_sentences_each_model(sentences2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Check the model predictions for the following sentences:\n",
    "1. [MASK] wrze w temperaturze 100 stopni, a zamarza w temeraturze 0 stopni Celsjusza.\n",
    "2. W wakacje odwiedziłem [MASK], który jest stolicą Islandii.\n",
    "3. Informatyka na [MASK] należy do najlepszych kierunków w Polsce."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences3 = [f\"[MASK] wrze w temperaturze 100 stopni, a zamarza w temeraturze 0 stopni Celsjusza.\",\n",
    "             f\"W wakacje odwiedziłem [MASK], który jest stolicą Islandii.\",\n",
    "             f\"Informatyka na [MASK] należy do najlepszych kierunków w Polsce.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert_cased_model\n",
      "   Woda wrze w temperaturze 100 stopni, a zamarza w temeraturze 0 stopni Celsjusza.\n",
      "   Mięso wrze w temperaturze 100 stopni, a zamarza w temeraturze 0 stopni Celsjusza.\n",
      "   Słońce wrze w temperaturze 100 stopni, a zamarza w temeraturze 0 stopni Celsjusza.\n",
      "   Nie wrze w temperaturze 100 stopni, a zamarza w temeraturze 0 stopni Celsjusza.\n",
      "   Piwo wrze w temperaturze 100 stopni, a zamarza w temeraturze 0 stopni Celsjusza.\n",
      "allegro/herbert-base-cased\n",
      "   Woda wrze w temperaturze 100 stopni, a zamarza w temeraturze 0 stopni Celsjusza.\n",
      "   Słońce wrze w temperaturze 100 stopni, a zamarza w temeraturze 0 stopni Celsjusza.\n",
      "   Ziemia wrze w temperaturze 100 stopni, a zamarza w temeraturze 0 stopni Celsjusza.\n",
      "   Następnie wrze w temperaturze 100 stopni, a zamarza w temeraturze 0 stopni Celsjusza.\n",
      "   Ciało wrze w temperaturze 100 stopni, a zamarza w temeraturze 0 stopni Celsjusza.\n",
      "allegro/herbert-klej-cased-v1\n",
      "   przedstawia wrze w temperaturze 100 stopni, a zamarza w temeraturze 0 stopni Celsjusza.\n",
      "   niewielkimi wrze w temperaturze 100 stopni, a zamarza w temeraturze 0 stopni Celsjusza.\n",
      "   sał wrze w temperaturze 100 stopni, a zamarza w temeraturze 0 stopni Celsjusza.\n",
      "   hat wrze w temperaturze 100 stopni, a zamarza w temeraturze 0 stopni Celsjusza.\n",
      "   otaczających wrze w temperaturze 100 stopni, a zamarza w temeraturze 0 stopni Celsjusza.\n",
      "\n",
      "\n",
      "bert_cased_model\n",
      "   W wakacje odwiedziłem kraj, który jest stolicą Islandii.\n",
      "   W wakacje odwiedziłem Cypr, który jest stolicą Islandii.\n",
      "   W wakacje odwiedziłem Meksyk, który jest stolicą Islandii.\n",
      "   W wakacje odwiedziłem Gibraltar, który jest stolicą Islandii.\n",
      "   W wakacje odwiedziłem Wellington, który jest stolicą Islandii.\n",
      "allegro/herbert-base-cased\n",
      "   W wakacje odwiedziłem Kraków, który jest stolicą Islandii.\n",
      "   W wakacje odwiedziłem Oslo, który jest stolicą Islandii.\n",
      "   W wakacje odwiedziłem Londyn, który jest stolicą Islandii.\n",
      "   W wakacje odwiedziłem Gdańsk, który jest stolicą Islandii.\n",
      "   W wakacje odwiedziłem Toruń, który jest stolicą Islandii.\n",
      "allegro/herbert-klej-cased-v1\n",
      "   W wakacje odwiedziłem Wyższego, który jest stolicą Islandii.\n",
      "   W wakacje odwiedziłem minimalnych, który jest stolicą Islandii.\n",
      "   W wakacje odwiedziłem zdrowotne, który jest stolicą Islandii.\n",
      "   W wakacje odwiedziłem dzu, który jest stolicą Islandii.\n",
      "   W wakacje odwiedziłem społecznymi, który jest stolicą Islandii.\n",
      "\n",
      "\n",
      "bert_cased_model\n",
      "   Informatyka na wsi należy do najlepszych kierunków w Polsce.\n",
      "   Informatyka na świecie należy do najlepszych kierunków w Polsce.\n",
      "   Informatyka na żywo należy do najlepszych kierunków w Polsce.\n",
      "   Informatyka na pewno należy do najlepszych kierunków w Polsce.\n",
      "   Informatyka na odległość należy do najlepszych kierunków w Polsce.\n",
      "allegro/herbert-base-cased\n",
      "   Informatyka na pewno należy do najlepszych kierunków w Polsce.\n",
      "   Informatyka na AGH należy do najlepszych kierunków w Polsce.\n",
      "   Informatyka na UW należy do najlepszych kierunków w Polsce.\n",
      "   Informatyka na studiach należy do najlepszych kierunków w Polsce.\n",
      "   Informatyka na UMK należy do najlepszych kierunków w Polsce.\n",
      "allegro/herbert-klej-cased-v1\n",
      "   Informatyka na spodziewnależy do najlepszych kierunków w Polsce.\n",
      "   Informatyka na oczekinależy do najlepszych kierunków w Polsce.\n",
      "   Informatyka na popadnależy do najlepszych kierunków w Polsce.\n",
      "   Informatyka na alnymi należy do najlepszych kierunków w Polsce.\n",
      "   Informatyka na kontrolowanego należy do najlepszych kierunków w Polsce.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predict_sentences_each_model(sentences3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Answer the following questions:\n",
    "1. Which of the models produced the best results?\n",
    "    \n",
    "    Na zmianę najlepszy był raz allegro/herbert-base-cased oraz dkleczek/bert-base-polish-cased-v1 w różnych zdaniach inny wypadał lepiej. Np. allegro był lepszy w zdaniu 'Na środku skrzyżowania widać ...', a dkleczek lepszy w zdaniu 'Witaj drogi ...'.\n",
    "    \n",
    "    \n",
    "2. Was any of the models able to capture Polish grammar?\n",
    "    \n",
    "    Tak. W szczególności dkleczek model był bezbłędny, co widać w szczególności w zdaniu 'Witaj drogi ...'. Natomiast allegro zwykle też sobie dobrze radził mimo drobnych potknięć np. właśnie w zdaniu 'Witaj drogi ...'. Ostatni model nie wyprodukował żadnego sensownego zdania, większość jest też niepoprawna.\n",
    "    \n",
    "    \n",
    "3. Was any of the models able to capture long-distant relationships between the words?\n",
    "    \n",
    "    Tak. Np. model allegro w zdaniu 'Informatyka na ... należy do najlepszych kierunków w Polsce.' podpowiedział 3 nazwy uczelni AGH, UW i UMK, a dkleczek model wyłapał tylko krótką relację.\n",
    "    \n",
    "    \n",
    "4. Was any of the models able to capture world knowledge?\n",
    "    \n",
    "    Nie za bardzo, chociaż momentami trochę tak. W zdaniu 'W wakacje odwiedziłem ..., który jest stolicą Islandii.' żaden model nie odpowiedział poprawnie. Ale w zdaniu '... wrze w tempertaturze 100 stopni, a zamarza w temeraturze 0 stopni Celsjusza.' modele allegro i dkleczek odpowiedziały poprawnie - 'Woda' i to na pierwszym miejscu.\n",
    "    \n",
    "    \n",
    "5. What are the most striking errors made by the models?\n",
    "    \n",
    "    Model allegro-klej wstawia czasem coś, co nawet nie jest słowem np. 'sał wrze w temperaturze 100 stopni, a zamarza w temeraturze 0 stopni Celsjusza.' albo słowa zupełnie nie na miejscu np. 'Te zabawki należą do zagłady.'. Pomijając ten model najbardziej rzucające się w oczy błędy: \n",
    "    * allegro: 'Warszawa to największe miasta.' - liczba mnoga\n",
    "    * allegro: 'Te zabawki należą do..' - wstawiona kropka, gdzie koniec zdania nie mógł wystąpić\n",
    "    * allegro: 'Właściciel samochodu widział złodzieja z włamaniem.' - błędna kolokacja\n",
    "    * allegro: 'Witaj drogi Łukasz.' - zła odmiana\n",
    "    * dkleczek: 'Na środku skrzyżowania widać ulicę.' - mniej uderzający błąd, ale jednak brak sensu    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
